```python
#
# EMR Backend: Secure Patient Document Upload
#
# This system provides a HIPAA-compliant API endpoint for uploading patient-related
# documents. It uses FastAPI, Pydantic, and SQLAlchemy, with JWT for
# authentication and role-based access control. Documents are stored in an
# encrypted AWS S3 bucket, and all actions are logged for auditing purposes.
#

# --- core/config.py ---

import os
from pydantic_settings import BaseSettings
from functools import lru_cache

class Settings(BaseSettings):
    """
    Application configuration settings loaded from environment variables.
    """
    # Application settings
    PROJECT_NAME: str = "EMR_DOCUMENT_SERVICE"
    API_V1_STR: str = "/api/v1"

    # Security settings
    # To generate a new secret: `openssl rand -hex 32`
    SECRET_KEY: str = os.getenv("SECRET_KEY", "09d25e094faa6ca2556c818166b7a9563b93f7099f6f0f4caa6cf63b88e8d3e7")
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60

    # Database settings
    # Example: postgresql+asyncpg://user:password@host:port/dbname
    DATABASE_URL: str = os.getenv("DATABASE_URL", "postgresql+asyncpg://emr_user:secure_password@localhost:5432/emr_db")

    # AWS S3 settings for document storage
    S3_BUCKET_NAME: str = os.getenv("S3_BUCKET_NAME", "emr-patient-documents-secure-bucket")
    S3_AWS_REGION: str = os.getenv("S3_AWS_REGION", "us-east-1")
    S3_AWS_ACCESS_KEY_ID: str = os.getenv("S3_AWS_ACCESS_KEY_ID", "minioadmin")
    S3_AWS_SECRET_ACCESS_KEY: str = os.getenv("S3_AWS_SECRET_ACCESS_KEY", "minioadmin")
    # Use MinIO for local development if S3_ENDPOINT_URL is set
    S3_ENDPOINT_URL: str | None = os.getenv("S3_ENDPOINT_URL", None) 

    class Config:
        case_sensitive = True
        env_file = ".env"

@lru_cache()
def get_settings():
    return Settings()

# --- db/base_class.py ---

from sqlalchemy.ext.declarative import as_declarative, declared_attr

@as_declarative()
class Base:
    """Base class for SQLAlchemy models."""
    id: any
    __name__: str

    # Generate __tablename__ automatically
    @declared_attr
    def __tablename__(cls) -> str:
        return cls.__name__.lower()

# --- db/session.py ---

from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

settings = get_settings()

engine = create_async_engine(settings.DATABASE_URL, pool_pre_ping=True, echo=False)
AsyncSessionLocal = sessionmaker(
    autocommit=False, 
    autoflush=False, 
    bind=engine, 
    class_=AsyncSession,
    expire_on_commit=False,
)

async def get_db() -> AsyncSession:
    """Dependency to get an async database session."""
    async with AsyncSessionLocal() as session:
        yield session

# --- models/user.py ---

import enum
from sqlalchemy import Column, Integer, String, Boolean, Enum
from db.base_class import Base

class UserRole(str, enum.Enum):
    ADMIN = "admin"
    CLINICIAN = "clinician"
    PATIENT = "patient"

class User(Base):
    """Database model for a user."""
    id = Column(Integer, primary_key=True, index=True)
    full_name = Column(String(255), nullable=False)
    email = Column(String(255), unique=True, index=True, nullable=False)
    hashed_password = Column(String(255), nullable=False)
    role = Column(Enum(UserRole), nullable=False)
    is_active = Column(Boolean(), default=True)


# --- models/document.py ---

from sqlalchemy import Column, Integer, String, DateTime, ForeignKey, BigInteger
from sqlalchemy.sql import func
from db.base_class import Base

class Document(Base):
    """Database model for a patient document."""
    id = Column(Integer, primary_key=True, index=True)
    patient_id = Column(Integer, index=True, nullable=False)
    uploader_user_id = Column(Integer, ForeignKey("user.id"), nullable=False)
    file_name = Column(String(255), nullable=False)
    s3_bucket = Column(String(255), nullable=False)
    s3_key = Column(String(255), unique=True, nullable=False)
    mime_type = Column(String(100), nullable=False)
    size_bytes = Column(BigInteger, nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())


# --- models/audit_log.py ---

from sqlalchemy import Column, Integer, String, DateTime, ForeignKey
from sqlalchemy.dialects.postgresql import JSONB
from sqlalchemy.sql import func
from db.base_class import Base

class AuditLog(Base):
    """Database model for audit trail entries."""
    id = Column(Integer, primary_key=True, index=True)
    timestamp = Column(DateTime(timezone=True), server_default=func.now())
    user_id = Column(Integer, ForeignKey("user.id"), nullable=True) # Nullable for system events
    action = Column(String(255), nullable=False)
    target_resource_type = Column(String(100), nullable=True)
    target_resource_id = Column(String(255), nullable=True)
    details = Column(JSONB) # Store additional context as JSON
    client_ip_address = Column(String(45), nullable=True)


# --- schemas/token.py ---

from pydantic import BaseModel
from typing import Optional

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    user_id: Optional[int] = None
    role: Optional[str] = None


# --- schemas/user.py ---

from pydantic import BaseModel, EmailStr
from models.user import UserRole

class UserBase(BaseModel):
    email: EmailStr
    full_name: str
    role: UserRole

class UserCreate(UserBase):
    password: str

class UserInDB(UserBase):
    id: int
    is_active: bool

    class Config:
        from_attributes = True

# --- schemas/audit_log.py ---

from pydantic import BaseModel
from typing import Optional, Any, Dict

class AuditLogCreate(BaseModel):
    user_id: Optional[int] = None
    action: str
    target_resource_type: Optional[str] = None
    target_resource_id: Optional[str] = None
    details: Dict[str, Any] = {}
    client_ip_address: Optional[str] = None

# --- schemas/document.py ---

from pydantic import BaseModel
from datetime import datetime

class DocumentBase(BaseModel):
    file_name: str
    mime_type: str
    size_bytes: int

class DocumentCreate(BaseModel):
    patient_id: int
    uploader_user_id: int
    file_name: str
    s3_bucket: str
    s3_key: str
    mime_type: str
    size_bytes: int

class DocumentResponse(BaseModel):
    id: int
    patient_id: int
    uploader_user_id: int
    file_name: str
    s3_bucket: str
    mime_type: str
    size_bytes: int
    created_at: datetime

    class Config:
        from_attributes = True


# --- crud/base.py ---

from typing import Any, Dict, Generic, List, Optional, Type, TypeVar, Union
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from db.base_class import Base

ModelType = TypeVar("ModelType", bound=Base)
CreateSchemaType = TypeVar("CreateSchemaType", bound=BaseModel)

class CRUDBase(Generic[ModelType, CreateSchemaType]):
    def __init__(self, model: Type[ModelType]):
        self.model = model

    async def get(self, db: AsyncSession, id: Any) -> Optional[ModelType]:
        result = await db.execute(select(self.model).filter(self.model.id == id))
        return result.scalars().first()

    async def create(self, db: AsyncSession, *, obj_in: CreateSchemaType) -> ModelType:
        obj_in_data = obj_in.model_dump()
        db_obj = self.model(**obj_in_data)
        db.add(db_obj)
        await db.commit()
        await db.refresh(db_obj)
        return db_obj


# --- crud/crud_user.py ---

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from crud.base import CRUDBase
from models.user import User
from schemas.user import UserCreate

class CRUDUser(CRUDBase[User, UserCreate]):
    async def get_by_email(self, db: AsyncSession, *, email: str) -> User | None:
        result = await db.execute(select(User).filter(User.email == email))
        return result.scalars().first()

crud_user = CRUDUser(User)

# --- crud/crud_document.py ---

from crud.base import CRUDBase
from models.document import Document
from schemas.document import DocumentCreate

class CRUDDocument(CRUDBase[Document, DocumentCreate]):
    pass

crud_document = CRUDDocument(Document)

# --- crud/crud_audit.py ---

from crud.base import CRUDBase
from models.audit_log import AuditLog
from schemas.audit_log import AuditLogCreate

class CRUDAuditLog(CRUDBase[AuditLog, AuditLogCreate]):
    async def log_action(self, db: AsyncSession, *, log_in: AuditLogCreate) -> AuditLog:
        return await self.create(db, obj_in=log_in)

crud_audit = CRUDAuditLog(AuditLog)

# --- services/s3_service.py ---

import boto3
from botocore.client import Config
from botocore.exceptions import ClientError
from fastapi import UploadFile, HTTPException, status
import logging

settings = get_settings()
logger = logging.getLogger(__name__)

class S3Service:
    def __init__(self):
        self.s3_client = boto3.client(
            's3',
            aws_access_key_id=settings.S3_AWS_ACCESS_KEY_ID,
            aws_secret_access_key=settings.S3_AWS_SECRET_ACCESS_KEY,
            region_name=settings.S3_AWS_REGION,
            endpoint_url=settings.S3_ENDPOINT_URL,
            config=Config(signature_version='s3v4')
        )
        self.bucket_name = settings.S3_BUCKET_NAME

    def upload_file(self, file: UploadFile, s3_key: str) -> None:
        """
        Uploads a file to an S3 bucket with server-side encryption.
        """
        try:
            self.s3_client.upload_fileobj(
                file.file,
                self.bucket_name,
                s3_key,
                ExtraArgs={
                    "ServerSideEncryption": "AES256",
                    "ContentType": file.content_type
                }
            )
        except ClientError as e:
            logger.error(f"S3 Upload Error for key {s3_key}: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Could not upload file to secure storage.",
            )

s3_service = S3Service()

# --- core/security.py ---

from datetime import datetime, timedelta
from typing import Optional
from jose import JWTError, jwt
from passlib.context import CryptContext
from fastapi import Depends, HTTPException, status, Request
from fastapi.security import OAuth2PasswordBearer
from sqlalchemy.ext.asyncio import AsyncSession

from core.config import get_settings
from db.session import get_db
from models.user import User, UserRole
from schemas.token import TokenData
from crud.crud_user import crud_user

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
settings = get_settings()

oauth2_scheme = OAuth2PasswordBearer(tokenUrl=f"{settings.API_V1_STR}/auth/token")

def verify_password(plain_password: str, hashed_password: str) -> bool:
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password: str) -> str:
    return pwd_context.hash(password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    return encoded_jwt

async def get_current_user(
    db: AsyncSession = Depends(get_db), token: str = Depends(oauth2_scheme)
) -> User:
    """
    Dependency to get the current user from a JWT token.
    Raises credentials_exception if token is invalid or user not found.
    """
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(
            token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM]
        )
        user_id: int = payload.get("sub")
        if user_id is None:
            raise credentials_exception
        token_data = TokenData(user_id=user_id)
    except JWTError:
        raise credentials_exception
    
    user = await crud_user.get(db, id=token_data.user_id)
    if user is None:
        raise credentials_exception
    return user

async def get_current_active_user(
    current_user: User = Depends(get_current_user),
) -> User:
    """
    Dependency to get the current active user.
    Raises an exception if the user is inactive.
    """
    if not current_user.is_active:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Inactive user")
    return current_user

def authorize_role(allowed_roles: list[UserRole]):
    """
    Dependency factory to authorize based on user role.
    """
    def role_checker(current_user: User = Depends(get_current_active_user)) -> User:
        if current_user.role not in allowed_roles:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="The user does not have sufficient privileges for this resource."
            )
        return current_user
    return role_checker

# --- api/v1/endpoints/auth.py ---

from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordRequestForm
from sqlalchemy.ext.asyncio import AsyncSession
from datetime import timedelta

from db.session import get_db
from core.security import create_access_token, verify_password
from crud.crud_user import crud_user
from schemas.token import Token

auth_router = APIRouter()

@auth_router.post("/token", response_model=Token)
async def login_for_access_token(
    db: AsyncSession = Depends(get_db), 
    form_data: OAuth2PasswordRequestForm = Depends()
):
    """
    OAuth2 compatible token login, get an access token for future requests.
    """
    user = await crud_user.get_by_email(db, email=form_data.username)
    if not user or not verify_password(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect email or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    if not user.is_active:
        raise HTTPException(status_code=400, detail="Inactive user")

    access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": str(user.id), "role": user.role.value},
        expires_delta=access_token_expires,
    )
    return {"access_token": access_token, "token_type": "bearer"}


# --- api/v1/endpoints/documents.py ---

import uuid
from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File, BackgroundTasks, Request
from sqlalchemy.ext.asyncio import AsyncSession

from db.session import get_db
from models.user import User, UserRole
from schemas.document import DocumentResponse, DocumentCreate
from schemas.audit_log import AuditLogCreate
from crud.crud_document import crud_document
from crud.crud_audit import crud_audit
from core.security import get_current_active_user, authorize_role
from services.s3_service import s3_service

documents_router = APIRouter()
ALLOWED_MIME_TYPES = ["application/pdf", "image/jpeg", "image/png", "text/plain"]
MAX_FILE_SIZE_MB = 10

def get_file_size_bytes(file: UploadFile) -> int:
    """Safely get file size from an UploadFile object."""
    file.file.seek(0, 2)
    size = file.file.tell()
    file.file.seek(0)
    return size

async def log_upload_action(
    db: AsyncSession,
    user: User,
    request: Request,
    document: DocumentResponse
):
    """Asynchronous background task to log the document upload event."""
    log_entry = AuditLogCreate(
        user_id=user.id,
        action="DOCUMENT_UPLOAD",
        target_resource_type="Document",
        target_resource_id=str(document.id),
        client_ip_address=request.client.host,
        details={
            "patient_id": document.patient_id,
            "filename": document.file_name,
            "s3_bucket": document.s3_bucket,
            "mime_type": document.mime_type,
            "size_bytes": document.size_bytes,
        }
    )
    # This must use a new session as the original request session is closed.
    async with AsyncSessionLocal() as session:
        await crud_audit.log_action(db=session, log_in=log_entry)


@documents_router.post(
    "/patients/{patient_id}/documents",
    response_model=DocumentResponse,
    status_code=status.HTTP_201_CREATED,
    dependencies=[Depends(authorize_role([UserRole.ADMIN, UserRole.CLINICIAN]))]
)
async def upload_patient_document(
    patient_id: int,
    request: Request,
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
):
    """
    Uploads a document for a specific patient.

    Requires authentication and authorization (Admin or Clinician roles).
    - Validates file type and size.
    - Uploads file to a secure, encrypted S3 bucket.
    - Creates a metadata record in the database.
    - Creates an audit log entry for the action.
    """
    if file.content_type not in ALLOWED_MIME_TYPES:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Invalid file type. Allowed types: {', '.join(ALLOWED_MIME_TYPES)}"
        )
    
    file_size_bytes = get_file_size_bytes(file)
    if file_size_bytes > MAX_FILE_SIZE_MB * 1024 * 1024:
        raise HTTPException(
            status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
            detail=f"File size exceeds the limit of {MAX_FILE_SIZE_MB} MB."
        )

    # In a real system, you would verify that the `patient_id` is valid
    # and that the `current_user` has privileges for this specific patient.
    # e.g., `await crud.patient.verify_access(db, user=current_user, patient_id=patient_id)`
    
    s3_key = f"patients/{patient_id}/{uuid.uuid4()}-{file.filename}"
    
    try:
        s3_service.upload_file(file=file, s3_key=s3_key)
    finally:
        await file.close()

    doc_in = DocumentCreate(
        patient_id=patient_id,
        uploader_user_id=current_user.id,
        file_name=file.filename,
        s3_bucket=settings.S3_BUCKET_NAME,
        s3_key=s3_key,
        mime_type=file.content_type,
        size_bytes=file_size_bytes
    )
    
    db_document = await crud_document.create(db=db, obj_in=doc_in)
    
    # Use response model to format output before passing to background task
    document_response = DocumentResponse.model_validate(db_document)

    background_tasks.add_task(
        log_upload_action, db, current_user, request, document_response
    )

    return document_response

# --- api/v1/api.py ---

from fastapi import APIRouter
from api.v1.endpoints import documents, auth

api_router = APIRouter()
api_router.include_router(auth.auth_router, prefix="/auth", tags=["Authentication"])
api_router.include_router(documents.documents_router, prefix="/documents", tags=["Patient Documents"])


# --- main.py ---

from fastapi import FastAPI
from starlette.middleware.cors import CORSMiddleware
from core.config import get_settings
from api.v1.api import api_router

settings = get_settings()

app = FastAPI(
    title=settings.PROJECT_NAME,
    openapi_url=f"{settings.API_V1_STR}/openapi.json",
    description="Backend for a secure, HIPAA-compliant EMR system.",
    version="1.0.0"
)

# Set all CORS enabled origins
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # For production, restrict this to trusted domains
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(api_router, prefix=settings.API_V1_STR)

@app.get("/", tags=["Root"])
async def read_root():
    """An endpoint to verify the service is running."""
    return {"status": "EMR Backend Service is operational."}

# To run this application:
# 1. Install dependencies:
#    pip install "fastapi[all]" "sqlalchemy[asyncio]" asyncpg pydantic-settings python-jose[cryptography] passlib[bcrypt] boto3
# 2. Set up environment variables in a .env file (see core/config.py)
# 3. Run with uvicorn:
#    uvicorn main:app --reload
#
# A one-time setup script would be needed to create initial users in the database.
```