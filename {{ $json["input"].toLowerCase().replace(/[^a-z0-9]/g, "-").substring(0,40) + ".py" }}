```python
# /core/config.py
import os
from pydantic_settings import BaseSettings
from typing import Set

class Settings(BaseSettings):
    """
    Application-wide settings managed by Pydantic.
    Values are loaded from environment variables.
    """
    PROJECT_NAME: str = "EMR Backend System"
    API_V1_STR: str = "/api/v1"

    # Security
    SECRET_KEY: str
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60
    # A set of allowed file content types for uploads
    ALLOWED_CONTENT_TYPES: Set[str] = {"application/pdf", "image/tiff", "application/dicom"}
    MAX_FILE_SIZE_MB: int = 50

    # Database
    DATABASE_URL: str

    # AWS S3 for Encrypted Storage
    S3_BUCKET_NAME: str
    S3_REGION: str
    AWS_ACCESS_KEY_ID: str
    AWS_SECRET_ACCESS_KEY: str
    # Set to 'AES256' for SSE-S3 or the KMS Key ID for SSE-KMS
    S3_SERVER_SIDE_ENCRYPTION: str = "AES256"

    class Config:
        case_sensitive = True
        env_file = ".env"

settings = Settings()

# /db/database.py
import databases
from sqlalchemy import create_engine, MetaData

DATABASE_URL = settings.DATABASE_URL
database = databases.Database(DATABASE_URL)
metadata = MetaData()
engine = create_engine(DATABASE_URL)

# /db/models.py
import uuid
from sqlalchemy import (
    Table, Column, String, DateTime, Boolean,
    ForeignKey, Enum as SQLAlchemyEnum, JSON
)
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.sql import func
from .database import metadata
import enum

class UserRole(str, enum.Enum):
    ADMIN = "admin"
    CLINICIAN = "clinician"
    NURSE = "nurse"
    PATIENT = "patient"
    SYSTEM = "system"

class AuditAction(str, enum.Enum):
    CREATE = "CREATE"
    READ = "READ"
    UPDATE = "UPDATE"
    DELETE = "DELETE"
    LOGIN_SUCCESS = "LOGIN_SUCCESS"
    LOGIN_FAIL = "LOGIN_FAIL"
    UPLOAD = "UPLOAD"
    DOWNLOAD = "DOWNLOAD"

users = Table(
    "users",
    metadata,
    Column("id", UUID(as_uuid=True), primary_key=True, default=uuid.uuid4),
    Column("username", String(255), unique=True, index=True, nullable=False),
    Column("email", String(255), unique=True, index=True, nullable=False),
    Column("hashed_password", String(255), nullable=False),
    Column("full_name", String(255), nullable=True),
    Column("roles", JSON, nullable=False, default=[]), # Stores a list of UserRole strings
    Column("is_active", Boolean, default=True),
    Column("created_at", DateTime(timezone=True), server_default=func.now()),
    Column("updated_at", DateTime(timezone=True), onupdate=func.now()),
)

medical_documents = Table(
    "medical_documents",
    metadata,
    Column("id", UUID(as_uuid=True), primary_key=True, default=uuid.uuid4),
    Column("patient_id", UUID(as_uuid=True), index=True, nullable=False),
    Column("uploader_user_id", UUID(as_uuid=True), ForeignKey("users.id"), nullable=False),
    Column("document_type", String(100), nullable=False),
    Column("original_filename", String(255), nullable=False),
    Column("content_type", String(100), nullable=False),
    Column("s3_object_key", String(1024), unique=True, nullable=False),
    Column("file_size_bytes", String, nullable=False),
    Column("upload_timestamp", DateTime(timezone=True), server_default=func.now()),
)

audit_logs = Table(
    "audit_logs",
    metadata,
    Column("id", UUID(as_uuid=True), primary_key=True, default=uuid.uuid4),
    Column("user_id", UUID(as_uuid=True), ForeignKey("users.id"), nullable=True), # Can be null for system events
    Column("action", SQLAlchemyEnum(AuditAction), nullable=False),
    Column("target_resource_type", String(100), nullable=True),
    Column("target_resource_id", String, nullable=True),
    Column("timestamp", DateTime(timezone=True), server_default=func.now()),
    Column("details", JSON, nullable=True), # e.g., IP address, user agent
    Column("status", String(50), nullable=False), # e.g., 'SUCCESS', 'FAILURE'
)

# /schemas/token.py
from pydantic import BaseModel
from typing import Optional
import uuid

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    username: Optional[str] = None
    user_id: Optional[uuid.UUID] = None

# /schemas/user.py
import uuid
from pydantic import BaseModel, EmailStr
from typing import List, Optional
from datetime import datetime
from db.models import UserRole

class UserBase(BaseModel):
    username: str
    email: EmailStr
    full_name: Optional[str] = None

class UserInDBBase(UserBase):
    id: uuid.UUID
    roles: List[UserRole]
    is_active: bool
    created_at: datetime
    updated_at: Optional[datetime] = None

    class Config:
        orm_mode = True

class User(UserInDBBase):
    pass

class UserInDB(UserInDBBase):
    hashed_password: str

# /schemas/document.py
import uuid
from pydantic import BaseModel, Field
from datetime import datetime

class DocumentUploadResponse(BaseModel):
    id: uuid.UUID
    patient_id: uuid.UUID
    s3_object_key: str
    upload_timestamp: datetime
    message: str = "Document uploaded successfully"

class DocumentMetadata(BaseModel):
    id: uuid.UUID
    patient_id: uuid.UUID
    uploader_user_id: uuid.UUID
    document_type: str
    original_filename: str
    content_type: str
    s3_object_key: str
    file_size_bytes: str
    upload_timestamp: datetime

    class Config:
        orm_mode = True

# /services/audit_service.py
import uuid
from fastapi import Request
from db.database import database
from db.models import audit_logs, AuditAction

class AuditService:
    @staticmethod
    async def log_event(
        user_id: uuid.UUID,
        action: AuditAction,
        status: str,
        target_resource_type: str,
        target_resource_id: str,
        request: Request
    ):
        """Creates an audit log entry."""
        details = {
            "ip_address": request.client.host,
            "user_agent": request.headers.get("user-agent"),
        }
        query = audit_logs.insert().values(
            user_id=user_id,
            action=action,
            status=status,
            target_resource_type=target_resource_type,
            target_resource_id=target_resource_id,
            details=details,
        )
        await database.execute(query)

audit_service = AuditService()

# /services/s3_service.py
import boto3
from botocore.exceptions import ClientError
from fastapi import UploadFile
from core.config import settings

class S3Service:
    def __init__(self):
        self.s3_client = boto3.client(
            's3',
            region_name=settings.S3_REGION,
            aws_access_key_id=settings.AWS_ACCESS_KEY_ID,
            aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY
        )
        self.bucket_name = settings.S3_BUCKET_NAME
        self.sse = settings.S3_SERVER_SIDE_ENCRYPTION

    async def upload_file(self, file: UploadFile, object_key: str) -> bool:
        """
        Uploads a file to an S3 bucket with server-side encryption.
        """
        try:
            extra_args = {'ServerSideEncryption': self.sse}
            self.s3_client.upload_fileobj(
                file.file,
                self.bucket_name,
                object_key,
                ExtraArgs=extra_args
            )
        except ClientError:
            # In a real system, log this error securely
            return False
        return True

s3_service = S3Service()

# /security/authentication.py
from datetime import datetime, timedelta, timezone
from typing import Optional, List
from fastapi import Depends, HTTPException, status, Request
from fastapi.security import OAuth2PasswordBearer
from jose import JWTError, jwt
from pydantic import ValidationError
import uuid

from core.config import settings
from db.database import database
from db.models import users, UserRole
from schemas.token import TokenData
from schemas.user import User
from services.audit_service import audit_service, AuditAction

oauth2_scheme = OAuth2PasswordBearer(tokenUrl=f"{settings.API_V1_STR}/auth/token")

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.now(timezone.utc) + expires_delta
    else:
        expire = datetime.now(timezone.utc) + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    # Ensure UUID is converted to string for JWT payload
    if 'user_id' in to_encode and isinstance(to_encode['user_id'], uuid.UUID):
        to_encode['user_id'] = str(to_encode['user_id'])
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    return encoded_jwt

async def get_user(username: str) -> Optional[User]:
    query = users.select().where(users.c.username == username)
    user_record = await database.fetch_one(query)
    if user_record:
        return User.from_orm(user_record)
    return None

async def get_current_user(token: str = Depends(oauth2_scheme)) -> User:
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
        token_data = TokenData(username=username)
    except (JWTError, ValidationError):
        raise credentials_exception
    
    user = await get_user(username=token_data.username)
    if user is None:
        raise credentials_exception
    return user

async def get_current_active_user(current_user: User = Depends(get_current_user)) -> User:
    if not current_user.is_active:
        raise HTTPException(status_code=400, detail="Inactive user")
    return current_user

def require_role(required_roles: List[UserRole]):
    """
    Dependency to enforce role-based access control (RBAC).
    """
    async def role_checker(request: Request, current_user: User = Depends(get_current_active_user)) -> User:
        user_roles = set(current_user.roles)
        if not any(role in user_roles for role in required_roles):
            # Audit the authorization failure
            await audit_service.log_event(
                user_id=current_user.id,
                action=AuditAction.UPDATE,
                status="FAILURE",
                target_resource_type="document_upload",
                target_resource_id=None,
                request=request
            )
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="The user does not have the required permissions.",
            )
        return current_user
    return role_checker

# /api/v1/endpoints/documents.py
import uuid
from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File, Form, Request
from sqlalchemy.dialects.postgresql import insert
from core.config import settings
from db.database import database
from db.models import medical_documents, UserRole
from schemas.document import DocumentUploadResponse
from schemas.user import User
from security.authentication import require_role
from services.s3_service import s3_service
from services.audit_service import audit_service, AuditAction

router = APIRouter()

@router.post(
    "/upload",
    response_model=DocumentUploadResponse,
    status_code=status.HTTP_201_CREATED,
    summary="Upload a Patient Medical Document",
    description="Securely uploads a medical document to encrypted storage and records metadata in the EMR.",
)
async def upload_document(
    request: Request,
    patient_id: uuid.UUID = Form(...),
    document_type: str = Form(...),
    file: UploadFile = File(...),
    current_user: User = Depends(require_role([UserRole.CLINICIAN, UserRole.NURSE, UserRole.ADMIN])),
):
    """
    Endpoint to upload a medical document for a patient.

    - **Requires Authentication**: Valid JWT for an active user.
    - **Requires Authorization**: User must have 'clinician', 'nurse', or 'admin' role.
    - **File Validation**: Checks content type and size against configured limits.
    - **Storage**: File is stored in an encrypted S3 bucket.
    - **Database**: Metadata is saved to the 'medical_documents' table.
    - **Auditing**: The upload action is logged.
    """
    # 1. Input Validation
    if file.content_type not in settings.ALLOWED_CONTENT_TYPES:
        raise HTTPException(
            status_code=status.HTTP_415_UNSUPPORTED_MEDIA_TYPE,
            detail=f"Unsupported file type. Allowed types are: {', '.join(settings.ALLOWED_CONTENT_TYPES)}",
        )

    file.file.seek(0, 2)
    file_size = file.file.tell()
    await file.seek(0)
    if file_size > settings.MAX_FILE_SIZE_MB * 1024 * 1024:
        raise HTTPException(
            status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
            detail=f"File size exceeds the limit of {settings.MAX_FILE_SIZE_MB}MB.",
        )

    # 2. Generate secure, unique object key for S3
    file_extension = file.filename.split('.')[-1] if '.' in file.filename else 'bin'
    s3_object_key = f"patients/{patient_id}/documents/{uuid.uuid4()}.{file_extension}"
    
    # 3. Upload to encrypted S3
    upload_successful = await s3_service.upload_file(file=file, object_key=s3_object_key)

    if not upload_successful:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to upload file to storage service.",
        )

    # 4. Insert metadata into the database within a transaction
    document_id = uuid.uuid4()
    db_insert_query = medical_documents.insert().values(
        id=document_id,
        patient_id=patient_id,
        uploader_user_id=current_user.id,
        document_type=document_type,
        original_filename=file.filename,
        content_type=file.content_type,
        s3_object_key=s3_object_key,
        file_size_bytes=str(file_size)
    )

    try:
        async with database.transaction():
             await database.execute(db_insert_query)
    except Exception as e:
        # In a real system, add structured logging here
        # Attempt to clean up the orphaned S3 file if DB write fails
        # s3_service.delete_file(s3_object_key)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to record document metadata.",
        )

    # 5. Log the successful audit event
    await audit_service.log_event(
        user_id=current_user.id,
        action=AuditAction.UPLOAD,
        status="SUCCESS",
        target_resource_type="medical_document",
        target_resource_id=str(document_id),
        request=request,
    )

    # 6. Return success response
    record = await database.fetch_one(medical_documents.select().where(medical_documents.c.id == document_id))

    return DocumentUploadResponse.from_orm(record)

# /api/v1/api.py
from fastapi import APIRouter
from api.v1.endpoints import documents

api_router = APIRouter()
api_router.include_router(documents.router, prefix="/documents", tags=["Documents"])

# /main.py
from fastapi import FastAPI
from db.database import database
from core.config import settings
from api.v1.api import api_router

app = FastAPI(
    title=settings.PROJECT_NAME,
    openapi_url=f"{settings.API_V1_STR}/openapi.json"
)

@app.on_event("startup")
async def startup():
    await database.connect()

@app.on_event("shutdown")
async def shutdown():
    await database.disconnect()

app.include_router(api_router, prefix=settings.API_V1_STR)

@app.get("/", include_in_schema=False)
def read_root():
    return {"status": "EMR Service is operational"}

```